{"cells":[{"cell_type":"markdown","metadata":{"id":"683c4808-d3bc-4d31-a8c2-e83127c3934a"},"source":["# Supervised Learning: Regression\n","---\n","\n","Pemateri:\n","- Deasy Indrawati\n","- Leonard Yulianus"]},{"cell_type":"markdown","metadata":{"id":"ccfacedc-a92c-4643-9ab3-032affab8f85"},"source":["## Classification vs. Regression"]},{"cell_type":"markdown","metadata":{"id":"afb60753-fe20-4c1d-9d9f-e781849f83f3"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","![Classification_Regression.png](attachment:1f1aa2bf-5360-439a-aa7d-cba60141e6c8.png)\n","\n","Regression adalah permasalahan prediksi dalam machine learning yang variabel targetnya berupa continuous value. Sedangkan, dalam classification variabel targetnya adalah kategori/label.\n","\n","\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n","Berikan contoh permasalahan klasifikasi dan regresi!\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"35c1b762-9aa9-4891-a420-5b47d0fbe46f"},"source":["Kita akan melihat berbagai jenis algoritma yang biasa digunakan untuk menyelesaikan permasalahan regresi. Untuk tujuan pembelajaran, kita akan menggunakan data dummy dengan 2 variabel, yaitu **X (independent variable/feature)** dan **y (dependent variable/target)**."]},{"cell_type":"markdown","metadata":{"id":"e9ee039c-61f9-4460-bb12-6b7b7f461d31"},"source":["## Generate Data Dummy"]},{"cell_type":"markdown","metadata":{"id":"8942ef56-87e3-4578-a38f-c25f31cca667"},"source":["Untuk generate data dummy, akan menggunakan formula $y = 3X^3 + 2X^2 + \\epsilon$\n","\n","generate 1000 data dengan rumus ini\n","epsilon: angka random kecil yang ditambahkan agar data tersebar\n","\n","akan dibuatkan x dan y agar lebih mudah dipahami"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"icrhI-SzbtnB"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9d609fc5-9c5d-4fd1-a466-359c57215023"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.rcParams['figure.figsize'] = (20,10)\n","plt.rcParams['font.size'] = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34544034-3571-4cb6-9807-907c75425dcb"},"outputs":[],"source":["np.random.seed(100)\n","X = np.random.rand(1000)\n","eps = np.random.normal(scale=0.25, size=1000)\n","y = 3 * X**3 + 2 * X**2 + eps\n","data = pd.DataFrame({'X': X, 'y': y})"]},{"cell_type":"markdown","metadata":{"id":"d4954638-8abf-4c5a-98d7-01eef142a699"},"source":["## Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{"id":"067f0f1d-89ad-43fc-b77b-cf6c5cdbddc0"},"source":["### Statistik Tentang Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d033c207-7824-4b07-a590-c06a3a3492ef"},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7c5f916-beaf-4628-b033-ca2dd976e83e"},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5c07bb7b-610c-4bef-9cb3-e39ecad5ee42"},"outputs":[],"source":["data.describe().T"]},{"cell_type":"markdown","metadata":{"id":"d75f0dee-318d-4493-92c5-884a0eb3e752"},"source":["### Plot Data"]},{"cell_type":"markdown","metadata":{"id":"7617b526-6d6f-43df-8cd6-d3632f61e6cf"},"source":["Karena data yang digunakan hanya terdiri dari 2 variabel, maka data dapat dengan mudah divisualisasikan menggunakan scatter plot."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e0c459a-a77d-438f-b127-58076e77f704"},"outputs":[],"source":["plt.scatter(x=data['X'], y=data['y'], alpha=0.5)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"5f564dac-f8f0-4624-9f2e-72cf648f8a9d"},"source":["### Cek Korelasi"]},{"cell_type":"markdown","metadata":{"id":"22822da1-0e3e-4b3e-8937-339483aa562b"},"source":["Perlu juga melakukan pengecekan korelasi antar variabel agar dapat melihat gambaran hubungan antar variabel. Korelasi positif berarti 2 variabel tersebut bergerak ke arah bersamaan. Korelasi negatif berarti ketika variabel yang 1 bertambah, variabel yang lain berkurang. \n","\n","\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Correlation\"\u003eCorrelation\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation\"\u003eCorrelation does not imply causation\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e23547c-e2c4-4afe-95b8-7027811716c6"},"outputs":[],"source":["sns.heatmap(data.corr(), annot=True)\n","plt.show()\n","#korelasi tinggi (hampir 1) karena data hanya ada 2 variable dan y dibentuk dari x"]},{"cell_type":"markdown","metadata":{"id":"5134e8fe-8dc0-4bcb-b20a-a093c7782067"},"source":["## Berbagai Jenis Algoritma Regresi"]},{"cell_type":"markdown","metadata":{"id":"5925a439-14eb-419d-b463-d951d4f85478"},"source":["### Split Dataset"]},{"cell_type":"markdown","metadata":{"id":"61e4efde-8bca-4ae5-9a65-7b328e42a589"},"source":["Untuk keperluan training dan testing model, data akan dibagi menjadi 2 bagian, yaitu **train data** dan **test data**.\n","\n","\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n","Mengapa dataset harus dibagi menjadi train data dan test data?\n","\u003c/div\u003e\n","\n","![Train_Test_Split.png](attachment:79925a41-1d28-490f-bb34-c3ed92252a9d.png)\n","\n","Selain membagi dataset dengan cara di atas, terdapat beberapa cara membagi dataset menjadi train data dan test data yang sering digunakan, antara lain:\n","- [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n","- [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html)\n","\n","\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/cross_validation.html\"\u003eCross-validation: evaluating estimator performance\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e\n","\n","note: kenapa split data? karena model harus diuji dulu lalu perform di data yang baru, kalau semua kalau jadi pengujian maka tidak ada pembuktian. model dianggap bagus kalau perform di data yang baru\n","\n","training data jangan sedikit, tp test data juga perlu jumlah yang mumpuni biar hasi pengujiannya lebih mendekati aslinya\n","\n","pembagian data ga harus 80% 20%. (baca KFold dan Shuffle Split)\n","KFold: misalnya data ada 3: maka data dibagi 3 dulu lalu salah satu dibagi 3 untuk test train, sisa 2nya jadi test-train dari model sebelumnya dimana sisa 2 ini juga dibagi 3 dengan test-train menggunakan posisi berbeda). real modeling pakai KFold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74eddcce-f687-44d2-a412-119466998298"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(data[['X']], data['y'], test_size=0.2, random_state=100)"]},{"cell_type":"markdown","metadata":{"id":"d502359d-94b9-4558-804e-7d3c1a817e1e"},"source":["### Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"9d9a346f-3c4a-43ed-8585-f1f6611ea960"},"source":["Linear regression mecoba menemukan persamaan linier yang paling dapat menjelaskan data, hal ini dilakukan dengan meminimalkan error prediksi.\n","\n","$$\\min{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n","\n","dimana\n","\n","$$\\hat{y}_i = w_0 + \\sum_{j=1}^{p} w_j X_{ij}$$\n","\n","\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://deepai.org/machine-learning-glossary-and-terms/ordinary-least-squares\"\u003eOrdinary Least Squares\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://www.cs.princeton.edu/courses/archive/fall18/cos324/files/linear-regression.pdf\"\u003eOrdinary Least Squares Linear Regression (pdf)\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://tungmphung.com/regularization-for-linear-regression/\"\u003eRegularization for Linear Regression\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e\n","\n","note: \n","meminimalkan error dengan membuat banyak model dan memilih eror terendah. jadi akan dibuat banyak model dari \"y\", maka dicari persamaan garis lurusnya\n","\n","kalau linear kurang kepake di data yang besar karena garis akan meningkat akibat peningkatan koefisien x"]},{"cell_type":"markdown","metadata":{"id":"e0a25cf4-1447-40f2-ad97-3605f4cb844d"},"source":["#### Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"af869cd8-4336-46da-a3ca-f17afa499b79"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"934c1a6f-669c-4d1b-9612-3f44726fd564"},"source":["\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\"\u003esklearn.linear_model.LinearRegression\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"13067607-41a5-4c77-aef5-50666abedd5a"},"source":["#### Cek Koefisien ($w$)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8011a26c-cc9c-4c42-a35b-68a35a71a6ec"},"outputs":[],"source":["print('Weight 0 = {:.3f}, Weight 1 = {:.3f}'.format(linreg.intercept_, linreg.coef_[0]))"]},{"cell_type":"markdown","metadata":{"id":"628a2c9d-3413-4b79-9403-e5c61468a6ec"},"source":["Model regresi linear yang didapatkan adalah $y_i = -0.963 + 4.759 X_i$\n","\n","Persamaan linier di atas dapat langsung digunakan untuk memprediksi $y$ dengan memasukkan nilai $X$.\n","Sebagai contoh, apabila $X = 2$, maka $y = -0.963 + 4.759 \\times 2$, sehingga $y = 8.555$.\n","\n","note: y= w0+w1\n","wo: intercept\n","w1: koefisien\n","maka akan dicari y dari koifisien"]},{"cell_type":"markdown","metadata":{"id":"2f749d84-5ff9-452d-8c1f-30c16d91f2a7"},"source":["#### Visualize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aea60e9-177d-45d0-8f45-b2f8c191c8ca"},"outputs":[],"source":["X_viz = pd.DataFrame({'X': np.linspace(0, 1, num=1000)})\n","y_viz = linreg.predict(X_viz)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8bfe2b02-7296-43a7-9f10-5907a485a3a8"},"outputs":[],"source":["plt.scatter(x=X_train['X'], y=y_train, alpha=0.5)\n","plt.title('Linear Regression')\n","plt.plot(X_viz['X'], y_viz, color='red')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"92032b6f-0e28-46a3-8ee9-4952ca11fcc9"},"source":["### Polynomial Regression"]},{"cell_type":"markdown","metadata":{"id":"1917a21f-17c2-4774-93b5-6c54148a101e"},"source":["Polynomial regression sebenarnya sama saja dengan linear regression, akan tetapi feature (X) di-transform menjadi beberapa features baru sesuai dengan polynomial degree yang ditentukan sebelum akhirnya features tersebut digunakan sebagai input pada linear regression.\n","\n","misalnya kalau X dibuat degree 3 maka x= x, x^2 dan x^3\n","jadi kolom x akan berrtambah seiring dengan penambahan degree\n","maka x jadi multivariat dan dimasukkan dalam rumus y=w0+wx\n","koefisien jadi 3\n","\n","hasilnya garis makin mendekati sebaran y. hasilnya features(x) akan tetap punya hubungan dengan label(y) tapi features dibuat jadi 3 dimana hubungan antar features  tidak linear (polynomial), ga mesti garis lurus tapi ga ada kondisi dimana ketika x naik dan y turun"]},{"cell_type":"markdown","metadata":{"id":"6c811c83-7c9b-481a-b196-6d400d3f201b"},"source":["#### Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2ed92db-b8d6-46b1-834d-85ec04ded983"},"outputs":[],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","\n","polyreg = make_pipeline(PolynomialFeatures(degree=3, include_bias=False),\n","                        LinearRegression())\n","polyreg.fit(X_train, y_train)\n","print('Jumlah features setelah transformasi PolynomialFeatures = {}'.format(polyreg.named_steps['polynomialfeatures'].n_output_features_))"]},{"cell_type":"markdown","metadata":{"id":"7c162dff-f26e-4a47-9180-7201a537ebc1"},"source":["Pada contoh di atas, dengan menggunakan parameter `degree=3`, variabel $X$ ditransformasikan menjadi 3 variabel, yaitu $X$, $X^2$, dan $X^3$.\n","\n","\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\"\u003esklearn.preprocessing.PolynomialFeatures\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html\"\u003esklearn.pipeline.make_pipeline\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"4876bdf3-81ce-4081-b0f7-2ac87ac33acb"},"source":["#### Cek Koefisien ($w$)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7443d116-63d6-4f3b-9aa9-42225fc48f33"},"outputs":[],"source":["print('Weight 0 = {:.3f}, Weight 1-3 = {}'.format(polyreg.named_steps['linearregression'].intercept_,\n","                                                  [round(x, 3) for x in polyreg.named_steps['linearregression'].coef_]))\n","\n","#akan muncul 3 koefisien\n","#maka akan mirip rumus y= 3x^3+2x^2+e"]},{"cell_type":"markdown","metadata":{"id":"27f477df-0c6f-4da0-899a-f91b01a9ba84"},"source":["Model regresi linear yang didapatkan adalah $y_i = -0.028 + 0.378 X_i + 1.281 {X_i}^2 + 3.332 {X_i}^3$"]},{"cell_type":"markdown","metadata":{"id":"fbd05663-f451-48e7-b1fb-786903447df2"},"source":["#### Visualize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"229eb191-c8c2-4958-8245-0627070c6271"},"outputs":[],"source":["X_viz = pd.DataFrame({'X': np.linspace(0, 1, num=1000)})\n","y_viz = polyreg.predict(X_viz)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e1e56bf-c6d6-4f75-a5bf-fdc57e8ad3b2"},"outputs":[],"source":["plt.scatter(x=X_train['X'], y=y_train, alpha=0.5)\n","plt.title('Polynomial Regression (degree=3)')\n","plt.plot(X_viz['X'], y_viz, color='red')\n","plt.show()\n","#hasilnya garis makin mendekati sebaran y. hasilnya features(x) akan tetap punya hubungan dengan label(y) tapi features dibuat jadi 3 \n","#dimana hubungan antar features  tidak linear (polynomial), ga mesti garis lurus tapi ga ada kondisi dimana ketika x naik dan y turun"]},{"cell_type":"markdown","metadata":{"id":"d75c2fbd-4f90-463e-b620-3bde91f9e4c7"},"source":["### Decision Tree Regressor"]},{"cell_type":"markdown","metadata":{"id":"3914ad32-59f0-4d72-9300-02e008eb26b5"},"source":["#### Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"797edb47-7b83-4c0f-9c86-5adcfc6dac30"},"outputs":[{"data":{"text/plain":["DecisionTreeRegressor()"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn import tree\n","\n","dtreg = tree.DecisionTreeRegressor(criterion='squared_error',\n","                                   max_depth=None, #berapa ke bawah\n","                                   min_samples_split=2, #cabangnya min brp\n","                                   min_samples_leaf=1,\n","                                   max_leaf_nodes=None)\n","dtreg.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"b08febf2-7e16-4822-a9ba-cb243fe942b5"},"source":["\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\"\u003esklearn.tree.DecisionTreeRegressor\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"99885351-d825-43f1-bb72-1e9a5152dc92"},"source":["#### Cek Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e7c23088-b80c-4cbd-80d5-5cbe8894e9ab"},"outputs":[],"source":["print('Decision tree memiliki depth = {} dan jumlah node = {}'.format(dtreg.tree_.max_depth, dtreg.tree_.node_count))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d897a6f1-2516-40ea-8bcc-618058bfe982"},"outputs":[],"source":["tree.plot_tree(dtreg, max_depth=2)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"c620d793-d31b-4ff2-97c9-9006632c4355"},"source":["#### Visualize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf682f59-6666-4b08-ae27-f300cb817144"},"outputs":[],"source":["X_viz = pd.DataFrame({'X': np.linspace(0, 1, num=1000)})\n","y_viz = dtreg.predict(X_viz)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8af03848-4924-41b4-a6cc-c512f639fdc3"},"outputs":[],"source":["plt.scatter(x=X_train['X'], y=y_train, alpha=0.5)\n","plt.title('Decision Tree Regressor')\n","plt.plot(X_viz['X'], y_viz, color='red')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"edb66748-8e07-4fab-9c47-5ad6e32bbcf5"},"source":["### Random Forest Regressor"]},{"cell_type":"markdown","metadata":{"id":"2207018e-3480-4e68-8081-4a3856d78d1d"},"source":["#### Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cab57a8-af2d-45d7-ae2c-098cade252c7"},"outputs":[],"source":["# termasuk ensemble method: bagging - random forest, boosting (setidaknya)\n","# ketika ada 1 data baru, data tsb masuk ke pohon2 tsb\n","# tiap pohon menghasilkan 1 prediksi lalu di agregat dlm bentuk rata2\n","from sklearn.ensemble import RandomForestRegressor\n","\n","rfreg = RandomForestRegressor(n_estimators=100, #banyaknya pohon\n","                              criterion='squared_error',\n","                              max_depth=None,\n","                              min_samples_split=2,\n","                              min_samples_leaf=1,\n","                              max_leaf_nodes=None,\n","                              bootstrap=True,\n","                              max_samples=0.5, #setiap pohon ditrain dgn data yg berbeda sebanyak 50% dari data = 800*50% = 400\n","                              random_state=100)\n","rfreg.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"7a02b0b0-c292-49c9-80f6-fef4cfb195d4"},"source":["\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\"\u003esklearn.ensemble.RandomForestRegressor\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Bootstrap_aggregating\"\u003eBootstrap aggregating\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"5836c8d3-f9e2-4684-ac83-e03af39ca561"},"source":["#### Visualize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4266a88c-a257-4b0c-b006-a5782197f619"},"outputs":[],"source":["X_viz = pd.DataFrame({'X': np.linspace(0, 1, num=1000)})\n","y_viz = rfreg.predict(X_viz)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6a56a46-ac85-4bf4-9375-0139d074937f"},"outputs":[],"source":["plt.scatter(x=X_train['X'], y=y_train, alpha=0.5)\n","plt.title('Random Forest Regressor')\n","plt.plot(X_viz['X'], y_viz, color='red')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"048cfcd4-3c29-4769-8277-a4c31f20e413"},"source":["### Neural Network"]},{"cell_type":"markdown","metadata":{"id":"W81qwrEEaA7y"},"source":["juga disebut universal function approximeter.\n","dengan cukup memberikan hidden layer dan nodes bisa memperkirakan dgn batas keakuratan tertentu"]},{"cell_type":"markdown","metadata":{"id":"064a96f3-d12c-4290-b108-c248e2d7902a"},"source":["![Neural_Network.png](attachment:7628729f-d984-4f2e-ae37-ab8598a00519.png)"]},{"cell_type":"markdown","metadata":{"id":"eabee8cc-ddbc-4139-82ea-a8f41e17aedc"},"source":["\u003cdiv class=\"alert alert-block alert-warning\"\u003e\n","Apa kegunaan activation function? Jenis-jenis activation function?\n","\u003c/div\u003e\n","tanpa activation function hanya kumpulan linear regression yg panjang pdhal data tidak selalu linear.\n","act function, membuat linear network menjadi tidak linear\n","tumpukan2 hidden layer itu lah yg menjadi tidak linear\n","contoh act function = sigmoid / logic function\n"]},{"cell_type":"markdown","metadata":{"id":"81LO7iVEYP1N"},"source":["input layer model neural network tergantung dimensi data kita\n","yang nentuin hidden layer adalah kita sebagai data sciencenya\n","hyper parameter tunning utk library mencari parameter yg optimal."]},{"cell_type":"markdown","metadata":{"id":"10e3887b-1565-4076-9895-db08541cafd6"},"source":["#### Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5b878a81-65b7-41fd-9c92-ba7ed9d8920e"},"outputs":[],"source":["from sklearn.neural_network import MLPRegressor\n","\n","nnreg = MLPRegressor(hidden_layer_sizes=(100), # hidden layer 1 tapi 100 ke bawah # (10,10) hidden layer nya 10, tiap layer ada 10 nodes\n","                     activation='relu', # klo f(x) 0 maka hasilnya nol, ga bisa di bawah\n","                     max_iter=5000, # menunggu sampe di 5000 iterasi klo belum selesai yah selsai di 5000\n","                     batch_size='auto',\n","                     random_state=100)\n","nnreg.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"ee6951f9-93a2-450a-8099-1381d65b5aff"},"source":["\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\"\u003esklearn.neural_network.MLPRegressor\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://www.v7labs.com/blog/neural-networks-activation-functions\"\u003e12 Types of Neural Network Activation Functions: How to Choose?\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"3bea4723-8d97-4e17-8163-3cf9ec594a5a"},"source":["#### Visualize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47e9af33-fe97-46f3-bca0-f52630c24f96"},"outputs":[],"source":["X_viz = pd.DataFrame({'X': np.linspace(0, 1, num=1000)})\n","y_viz = nnreg.predict(X_viz)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40ae2a24-1ea3-44c2-842a-0ea4245ac08c"},"outputs":[],"source":["plt.scatter(x=X_train['X'], y=y_train, alpha=0.5)\n","plt.title('Neural Network')\n","plt.plot(X_viz['X'], y_viz, color='red')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ae6c3d48-9679-44ed-a696-319222c7152a"},"source":["## Evaluasi Model"]},{"cell_type":"markdown","metadata":{"id":"884d7c21-063a-4bd7-9cca-2d63fd41f4b9"},"source":["### Underfitting vs. Overfitting"]},{"cell_type":"markdown","metadata":{"id":"5d2d6a85-5bae-45a7-b91b-f6e912dbc09b"},"source":["![Underfitting_Overfitting.png](attachment:52ca007c-15c2-499c-95d0-6d8de0fdcbf2.png)\n","\n","Model dengan high bias tetapi low variance akan memiliki kecenderungan untuk underfit, sedangkan model dengan low bias tetapi high variance akan memiliki kecenderungan untuk overfit. Target utamanya adalah membuat model yang memiliki low bias dan low variance.\n","\n","\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff\"\u003eBias–variance tradeoff\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"markdown","metadata":{"id":"c075109a-3223-4345-ae49-1cf88f76c9f1"},"source":["### Metrics"]},{"cell_type":"markdown","metadata":{"id":"9444195a-1b3f-4481-bb69-e673527ed71e"},"source":["Terdapat beberapa metrics yang umum digunakan untuk mengukur kemampuan prediksi model regresi, antara lain:\n","- $R^2$ (Coefficient of Determination) #max 1, makin besar makin bagus\n","$$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y}_i)^2}$$\n","- MSE (Mean Squared Error) #makin kecil makin bagus\n","$$\\text{MSE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n","- RMSE (Root Mean Squared Error) #makin kecil makin bagus\n","$$\\text{RMSE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\sqrt{(y_i - \\hat{y}_i)^2}$$\n","- MAE (Mean Absolute Error) #makin kecil makin bagus\n","$$\\text{MAE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|$$\n","- MAPE (Mean Absolute Percentage Error) #makin kecil makin bagus\n","$$\\text{MAPE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\left| y_i - \\hat{y}_i \\right|}{\\max{(\\epsilon, \\left| y_i \\right|)}}$$\n","\n","\u003cdiv class=\"alert alert-block alert-info\"\u003e\n","Baca lebih lanjut:\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\"\u003eRegression Metrics\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\u003c/div\u003e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b54ebd09-c9f2-48bb-b28b-5dfa9d582a6e"},"outputs":[],"source":["from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","\n","def calculate_metrics(y_true, y_pred):\n","    r2 = r2_score(y_true, y_pred)\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = mean_squared_error(y_true, y_pred, squared=False)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    return [r2, mse, rmse, mae, mape]\n","    \n","# helper function untuk menampilkan beberapa metrics sekaligus\n","def print_regression_metrics(model_name, y_true, y_pred):\n","    r2, mse, rmse, mae, mape = calculate_metrics(y_true, y_pred)\n","    \n","    print('Evaluasi Performa Model: {}'.format(model_name))\n","    print('R squared: {:.2f}'.format(r2))\n","    print('MSE: {:.2f}'.format(mse))\n","    print('RMSE: {:.2f}'.format(rmse))\n","    print('MAE: {:.2f}'.format(mae))\n","    print('MAPE: {:.2f}'.format(mape))\n","    print()\n","    \n","    return [r2, mse, rmse, mae, mape]"]},{"cell_type":"markdown","metadata":{"id":"b4499724-c6ae-4bbd-bb9c-bf464fe93f7e"},"source":["### Evaluasi Model Regresi"]},{"cell_type":"markdown","metadata":{"id":"b00f1d6b-890b-4035-952e-80c22a1cf507"},"source":["#### Linear Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8be21fff-3fa8-440a-870c-3c0bc538f4e2"},"outputs":[],"source":["y_train_linreg = linreg.predict(X_train)\n","linreg_train_scores = print_regression_metrics('Linear Regression (Train Data)', y_train, y_train_linreg)\n","\n","y_test_linreg = linreg.predict(X_test)\n","linreg_test_scores = print_regression_metrics('Linear Regression (Test Data)', y_test, y_test_linreg)\n","\n","linreg_scores = {'metric_name': ['R squared', 'MSE', 'RMSE', 'MAE', 'MAPE'],\n","                 'train': linreg_train_scores,\n","                 'test': linreg_test_scores}\n","scores_df = pd.DataFrame(linreg_scores)\n","scores_df.plot.bar(x='metric_name', figsize=(20, 5))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"30c7b60b-1010-4cd2-9934-62b2030bcae4"},"source":["#### Polynomial Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9e8e9c5-002c-4d49-bf9c-d22c8ca3fb15"},"outputs":[],"source":["y_train_polyreg = polyreg.predict(X_train)\n","polyreg_train_scores = print_regression_metrics('Polynomial Regression (Train Data)', y_train, y_train_polyreg)\n","\n","y_test_polyreg = polyreg.predict(X_test)\n","polyreg_test_scores = print_regression_metrics('Polynomial Regression (Test Data)', y_test, y_test_polyreg)\n","\n","polyreg_scores = {'metric_name': ['R squared', 'MSE', 'RMSE', 'MAE', 'MAPE'],\n","                  'train': polyreg_train_scores,\n","                  'test': polyreg_test_scores}\n","scores_df = pd.DataFrame(polyreg_scores)\n","scores_df.plot.bar(x='metric_name', figsize=(20, 5))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"5e62df44-36cf-4ba0-b7af-0a2bd5a75bac"},"source":["#### Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcb89285-da38-421a-82b4-f05b2c6566c1"},"outputs":[],"source":["y_train_dtreg = dtreg.predict(X_train)\n","dtreg_train_scores = print_regression_metrics('Decision Tree Regressor (Train Data)', y_train, y_train_dtreg)\n","\n","y_test_dtreg = dtreg.predict(X_test)\n","dtreg_test_scores = print_regression_metrics('Decision Tree Regressor (Test Data)', y_test, y_test_dtreg)\n","\n","dtreg_scores = {'metric_name': ['R squared', 'MSE', 'RMSE', 'MAE', 'MAPE'],\n","                'train': dtreg_train_scores,\n","                'test': dtreg_test_scores}\n","scores_df = pd.DataFrame(dtreg_scores)\n","scores_df.plot.bar(x='metric_name', figsize=(20, 5))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"0c004784-1bc5-4dd0-a565-9fd5521fda00"},"source":["#### Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd96f48c-5c8b-476f-bb03-c4969b4832c2"},"outputs":[],"source":["y_train_rfreg = rfreg.predict(X_train)\n","rfreg_train_scores = print_regression_metrics('Random Forest Regressor (Train Data)', y_train, y_train_rfreg)\n","\n","y_test_rfreg = rfreg.predict(X_test)\n","rfreg_test_scores = print_regression_metrics('Random Forest Regressor (Test Data)', y_test, y_test_rfreg)\n","\n","rfreg_scores = {'metric_name': ['R squared', 'MSE', 'RMSE', 'MAE', 'MAPE'],\n","                'train': rfreg_train_scores,\n","                'test': rfreg_test_scores}\n","scores_df = pd.DataFrame(rfreg_scores)\n","scores_df.plot.bar(x='metric_name', figsize=(20, 5))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"e5e9b9a9-1ea1-4a26-b9d6-b49e17824b40"},"source":["#### Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1069b64-91bd-48f8-a3cb-4f4e7e3be7a2"},"outputs":[],"source":["y_train_nnreg = nnreg.predict(X_train)\n","nnreg_train_scores = print_regression_metrics('Neural Network (Train Data)', y_train, y_train_nnreg)\n","\n","y_test_nnreg = nnreg.predict(X_test)\n","nnreg_test_scores = print_regression_metrics('Neural Network (Test Data)', y_test, y_test_nnreg)\n","\n","nnreg_scores = {'metric_name': ['R squared', 'MSE', 'RMSE', 'MAE', 'MAPE'],\n","                'train': nnreg_train_scores,\n","                'test': nnreg_test_scores}\n","scores_df = pd.DataFrame(nnreg_scores)\n","scores_df.plot.bar(x='metric_name', figsize=(20, 5))\n","plt.show()"]}],"metadata":{"colab":{"name":"7_2. Regression Tutorial.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}